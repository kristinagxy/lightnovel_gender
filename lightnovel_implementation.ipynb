{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lightnovel_get_power.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZxx1Hq3dNxL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "from os import path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# implementation"
      ],
      "metadata": {
        "id": "RYMXY1Nde--W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set up"
      ],
      "metadata": {
        "id": "eQOjOlhIdlxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install booknlp"
      ],
      "metadata": {
        "id": "3e1MKtaCeHpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "yeZgkgHUeD7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from booknlp.booknlp import BookNLP\n",
        "model_params={\n",
        "\t\t\"pipeline\":\"entity,quote,event,coref\", \n",
        "\t\t\"model\":\"small\" \n",
        "\t}\n",
        "\n",
        "booknlp = BookNLP(\"en\", model_params)"
      ],
      "metadata": {
        "id": "Yebfcixcdk_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/light_novel_original.zip"
      ],
      "metadata": {
        "id": "dn1oVJ7cdWq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the list of series in the corpus\n",
        "series_list = os.listdir(f\"/content/light_novel\")\n",
        "series_list = [i for i in series_list if not i.startswith(\".\")]"
      ],
      "metadata": {
        "id": "C9CRg86Ovatu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## methods"
      ],
      "metadata": {
        "id": "RRh71FgNubee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "X3VKieCF2wVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_last_digit(string):\n",
        "  # return the number at the end of a string\n",
        "  # the numbers can be at most two digits\n",
        "  # e.g. find_last_digit(\"string12\") = 12\n",
        "  #      find_last_digit(\"string2\") = 2\n",
        "\n",
        "  s = re.findall(\"[0-9]{1,2}\", string)\n",
        "  return int(s[-1])"
      ],
      "metadata": {
        "id": "_UqhyPD_eBDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_chapters(chapter_list):\n",
        "  # sort a list of chapters in ascending order\n",
        "  \n",
        "  return sorted(chapter_list,key = find_last_digit)"
      ],
      "metadata": {
        "id": "irU23jcwueMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def proc(filename):\n",
        "  # loading a file and return in json format\n",
        "  \n",
        "  with open(filename) as file:\n",
        "    data=json.load(file)\n",
        "  return data"
      ],
      "metadata": {
        "id": "KI0_8Wf8ugan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_in_mention(current_mention, target_mention):\n",
        "  # check if the current character is one of the target characters by matching mentions\n",
        "\n",
        "  current_mention_list = [i[\"n\"] for i in current_mention]\n",
        "  for i in current_mention_list:\n",
        "    for key,a in target_mention.items():\n",
        "      for b in a:\n",
        "        if i == b:\n",
        "          return key\n",
        "  return -1"
      ],
      "metadata": {
        "id": "2Ij36nxTutVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_counter_from_dependency_list(dep_list):\n",
        "    # return a dictionary in the form of token: token counts\n",
        "    counter=Counter()\n",
        "    for token in dep_list:\n",
        "        term=token[\"w\"]\n",
        "        tokenGlobalIndex=token[\"i\"]\n",
        "        counter[term]+=1\n",
        "    return counter"
      ],
      "metadata": {
        "id": "Fs2WDnnJuwmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_lemma(word):\n",
        "  doc = nlp(word)\n",
        "  a = \"\"\n",
        "  for x in range(len(doc)):\n",
        "    if x == 0:\n",
        "      a += doc[x].lemma_\n",
        "    else:\n",
        "      a += \" \"\n",
        "      a += doc[x].lemma_\n",
        "  return a"
      ],
      "metadata": {
        "id": "PgsJigMWu2YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_agent_patient(data,target_mentions):\n",
        "  # get agent and patient information of a list of target charcters\n",
        "\n",
        "  character_agent_patient = []\n",
        "  for character in data[\"characters\"]:\n",
        "    \n",
        "    agentList=character[\"agent\"]\n",
        "    patientList=character[\"patient\"]\n",
        "\n",
        "\n",
        "    mentions=character[\"mentions\"]\n",
        "    proper_mentions=mentions[\"proper\"]\n",
        "\n",
        "    character_information = {}\n",
        "\n",
        "    # check if the characters have proper mentions first, then check whether the character is one of the target characters\n",
        "    if len(mentions[\"proper\"]) > 0 and check_in_mention(proper_mentions,target_mentions) != -1:\n",
        "\n",
        "        character_information[\"name\"] = check_in_mention(proper_mentions,target_mentions)\n",
        "\n",
        "        printTop=None\n",
        "\n",
        "        agent_dict = {}\n",
        "        patient_dict = {}\n",
        "\n",
        "        for k, v in get_counter_from_dependency_list(agentList).most_common(printTop):\n",
        "            k = make_lemma(k)\n",
        "            agent_dict[k] = v\n",
        "       \n",
        "\n",
        "        for k, v in get_counter_from_dependency_list(patientList).most_common(printTop):\n",
        "            k = make_lemma(k)\n",
        "            patient_dict[k] = v\n",
        "       \n",
        "\n",
        "        character_information[\"agent\"] = agent_dict\n",
        "        character_information[\"patient\"] = patient_dict\n",
        "    if character_information != {}:\n",
        "      character_agent_patient.append(character_information)\n",
        "      \n",
        "  return character_agent_patient"
      ],
      "metadata": {
        "id": "B9zQctfHvBTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_power(character):\n",
        "  # calculate the power of a character using the power frames lexicon\n",
        "  # input: a dictionary \"character_information\" (as in the get_agent_patient function)\n",
        "\n",
        "  agent = character[\"agent\"]\n",
        "  patient = character[\"patient\"]\n",
        "\n",
        "  length = 0\n",
        "  power = 0\n",
        "\n",
        "  # verbs for which the character is the agent\n",
        "  for i in list(agent.keys()):\n",
        "    length += agent[i]\n",
        "    if i in list(agency_power[\"verb\"]):\n",
        "      index = list(agency_power[\"verb\"]).index(i)\n",
        "      if index != -1:\n",
        "        if agency_power[\"power\"][index] == \"power_agent\":\n",
        "          power += 1 * agent[i]\n",
        "        elif agency_power[\"power\"][index] == \"power_theme\":\n",
        "          power -= 1 * agent[i]\n",
        "\n",
        "  # verbs for which the character is the patient\n",
        "  for i in list(patient.keys()):\n",
        "    length += patient[i]\n",
        "    if i in list(agency_power[\"verb\"]):\n",
        "      index = list(agency_power[\"verb\"]).index(i)\n",
        "      if index != -1:\n",
        "        if agency_power[\"power\"][index] == \"power_agent\":\n",
        "          power -= 1 * patient[i]\n",
        "        elif agency_power[\"power\"][index] == \"power_theme\":\n",
        "          power += 1 * patient[i]\n",
        "  try:\n",
        "    normalized_power = power/length # normalize the power\n",
        "  except:\n",
        "    normalized_power = \"/\"\n",
        "\n",
        "  return normalized_power"
      ],
      "metadata": {
        "id": "kvDyTmb4vG7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For each volume, get the power scores for the major characters from agent and patient verbs, and store them in a dataframe along with general information about the volume and the characters"
      ],
      "metadata": {
        "id": "_MOyVfglG78C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the names for the splitted parts in the volume that are also shown in the name of output files by booknlp\n",
        "five_parts = [\"splitted_textaa\",\"splitted_textab\",\"splitted_textac\",\"splitted_textad\",\"splitted_textae\"]"
      ],
      "metadata": {
        "id": "Yxi6sERtupwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "TSRsoYFDvMBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "r = re.compile(r'output_splitted.*')"
      ],
      "metadata": {
        "id": "KsuJ1tx822q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict = pickle.load(open('/content/all_dict.pickle', 'rb'))\n",
        "agency_power = pd.read_csv(\"/content/agency_power_lemma.csv\")"
      ],
      "metadata": {
        "id": "E2zJMRNP2-Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for series in series_list:\n",
        "\n",
        "\n",
        "  volume_list = os.listdir(f\"light_novel/{series}\")\n",
        "  volume_list = [i for i in volume_list if i.startswith('Volume')]\n",
        "\n",
        "  print(f\"processing {series}\")\n",
        "\n",
        "  for volume in volume_list:\n",
        "    print(f\"processing {series} {volume}\")\n",
        "\n",
        "    # get the chapter lists for the volume\n",
        "    chapter_list = os.listdir(f\"light_novel/{series}/{volume}\")\n",
        "    chapter_list = [i for i in chapter_list if not i.startswith('.')]\n",
        "\n",
        "    # write the full text (whole book) into a file\n",
        "    fulltext = \"\"\n",
        "    for i in sort_chapters(chapter_list):\n",
        "      with open(f\"light_novel/{series}/{volume}/{i}\") as f:\n",
        "        fulltext += f.read()\n",
        "\n",
        "    with open(f\"light_novel/{series}/{volume}/full_text\", 'w') as f:\n",
        "      f.write(fulltext)\n",
        "    \n",
        "    # split the full texts into five nearly equal parts\n",
        "    a = f\"/content/light_novel/{series}/{volume}/full_text\"\n",
        "    b = f\"/content/light_novel/{series}/{volume}/splitted_text\"\n",
        "\n",
        "    !split -n l/5 {a} {b}\n",
        "\n",
        "    # process the whole book with booknlp\n",
        "    inputFile=f\"/content/light_novel/{series}/{volume}/full_text\"\n",
        "    outputDir=f\"/content/light_novel/{series}/{volume}/{series}_{volume}_output\"\n",
        "    idd=f\"{series}_{volume}\"\n",
        "\n",
        "    booknlp.process(inputFile, outputDir, idd)\n",
        "\n",
        "    # get the 9 characters with the largest number of mention counts (these are the major characters)\n",
        "    data=proc(f\"{outputDir}/{idd}.book\")\n",
        "    character_count={}\n",
        "    for i in data[\"characters\"]:\n",
        "      character_id=i[\"id\"]\n",
        "      mention = i[\"mentions\"][\"proper\"]\n",
        "      count=i[\"count\"]\n",
        "      if len(mention) > 0:\n",
        "        character_count[character_id] = count\n",
        "\n",
        "\n",
        "      top_9 = sorted(list(character_count.values()))[-9:]\n",
        "      # record the ids for the top 9 major characters\n",
        "      max_keys = [k for k, v in character_count.items() if v in top_9]\n",
        "\n",
        "\n",
        "      \n",
        "    character_list = []\n",
        "    mentions = {}\n",
        "\n",
        "    for i in data[\"characters\"]:\n",
        "\n",
        "      character_information = {}\n",
        "      mention = i[\"mentions\"][\"proper\"] # record proper mention of the character\n",
        "      referential_gender_distribution=referential_gender_prediction=\"unknown\"\n",
        "\n",
        "      if i[\"g\"] is not None and i[\"g\"] != \"unknown\":\n",
        "          referential_gender_distribution=i[\"g\"][\"inference\"]\n",
        "          referential_gender=i[\"g\"][\"argmax\"] # record the referential gender of the character by taking argmax\n",
        "\n",
        "      # check if is one of the major characters by matching the id\n",
        "      if len(mention) >0 and i[\"id\"] in max_keys:\n",
        "        max_proper_mention=mention[0][\"n\"]\n",
        "        character_information[\"name\"] = max_proper_mention # set the name to be the proper mention that is used most often\n",
        "        character_information[\"gender\"] = referential_gender # set the gender\n",
        "        if character_information != {}:\n",
        "          character_list.append(character_information) # add information of the character to the character_list\n",
        "        # record all proper mentions for the character, and save this to the dictionary \"mentions\"\n",
        "        mentions[mention[0][\"n\"]] = [i[\"n\"] for i in mention] \n",
        "\n",
        "    # create a dataframe for storing character information\n",
        "    character_list = pd.DataFrame(character_list)\n",
        "\n",
        "    arr = np.array(character_list[\"gender\"])\n",
        "    if np.all(arr == arr[0]):\n",
        "      continue # if all major characters are from the same gender, skip this volume as it does not give any comparisons\n",
        "\n",
        "    # set up basic structure of the dataframe, and put in information about the volume and series\n",
        "    power_df = character_list.copy()\n",
        "    power_df[[\"power1\",\"power2\",\"power3\",\"power4\",\"power5\"]] = 0\n",
        "    power_df[\"series_name\"] = f\"{series}\"\n",
        "    power_df[\"volume_name\"] = f\"{volume}\"\n",
        "    power_df[\"genre\"] = str(my_dict[f\"{series}\"][\"genre\"])\n",
        "    m = 0\n",
        "\n",
        "    # start processing the five splitted parts with booknlp\n",
        "    for i in five_parts:\n",
        "      inputFile = f\"/content/light_novel/{series}/{volume}/{i}\"\n",
        "      outputDir = f\"/content/light_novel/{series}/{volume}/output_{i}\"\n",
        "      idd = f\"{series}_{volume}_{i}\"\n",
        "\n",
        "      if any(s==f\"output_{i}\" for s in os.listdir(f\"light_novel/{series}/{volume}\")) == False:\n",
        "        booknlp.process(inputFile, outputDir, idd)\n",
        "\n",
        "      data=proc(f\"{outputDir}/{idd}.book\")\n",
        "      # write the calculated power scores at each stage for the characters to the dataframe\n",
        "      power_list = {}\n",
        "      for character in get_agent_patient(data,mentions):\n",
        "        power_list[character[\"name\"]] = calculate_power(character)\n",
        "      for a in range(9):\n",
        "        current_name = power_df.iloc[a,0]\n",
        "        try:\n",
        "          power_df.iloc[a,2+m] = power_list[current_name]\n",
        "        except:\n",
        "          power_df.iloc[a,2+m] = \"/\"\n",
        "      m+=1\n",
        "\n",
        "      # print(power_df)\n",
        "    power_df.to_csv(f'/content/light_novel/{series}/{volume}/{series}_{volume}_power_df_new.csv', index = False)"
      ],
      "metadata": {
        "id": "FWwZmN7LnmTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r /content/light_novel_0701.zip /content/light_novel"
      ],
      "metadata": {
        "id": "Tp1Y5H0GakTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an empty dataframe to gather the result from all volumes in the corpus\n",
        "power = pd.DataFrame(columns = [\"name\",\"gender\",\"power1\",\"power2\",\"power3\",\"power4\",\"power5\",\"series_name\",\"volume_name\",\"genre\"])"
      ],
      "metadata": {
        "id": "YXQYDtM-cLuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for series in series_list:\n",
        "\n",
        "  volume_list = os.listdir(f\"/content/light_novel/{series}\")\n",
        "  volume_list = [i for i in volume_list if i.startswith('Volume')]\n",
        "\n",
        "  print(f\"processing {series}\")\n",
        "\n",
        "  for volume in volume_list:\n",
        "    print(f\"processing {series} {volume}\")\n",
        "\n",
        "    try: \n",
        "      mycsv = pd.read_csv(f\"/content/light_novel/{series}/{volume}/{series}_{volume}_power_df_new.csv\")\n",
        "      power = pd.concat([power, mycsv], ignore_index = True, axis = 0)\n",
        "    except:\n",
        "      continue"
      ],
      "metadata": {
        "id": "LAKwDYJGbtrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "power.to_csv('/content/power_normalized_new.csv', index = False)"
      ],
      "metadata": {
        "id": "yEcswR2mcg-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## get modifier and possessions of the major characters"
      ],
      "metadata": {
        "id": "uq1OHcS5ecOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mod_pos(series,volume,name):\n",
        "  # input: series name, volume name, name of character\n",
        "  # output: top 10 poss and top 10 mod\n",
        "  data = proc(f\"/content/light_novel/{series}/{volume}/{series}_{volume}_output/{series}_{volume}.book\")\n",
        "\n",
        "  # check if it is one of the major characters\n",
        "  for character in data[\"characters\"]:\n",
        "    if len(character[\"mentions\"][\"proper\"]) == 0 or character[\"mentions\"][\"proper\"][0][\"n\"] != name:\n",
        "      continue\n",
        "\n",
        "    possList=character[\"poss\"]\n",
        "    modList=character[\"mod\"]\n",
        "\n",
        "    mod_dict = {}\n",
        "    poss_dict = {}\n",
        "\n",
        "    printTop = None\n",
        "\n",
        "    for k, v in get_counter_from_dependency_list(possList).most_common(printTop):\n",
        "      k = make_lemma(k)\n",
        "      poss_dict[k] = v\n",
        "       \n",
        "\n",
        "    for k, v in get_counter_from_dependency_list(modList).most_common(printTop):\n",
        "      k = make_lemma(k)\n",
        "      mod_dict[k] = v\n",
        "\n",
        "  return poss_dict,mod_dict"
      ],
      "metadata": {
        "id": "XoaBoD6RefQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write the modifer and possession information to the dataframe\n",
        "\n",
        "power[[\"poss\",\"mod\"]] = 0\n",
        "\n",
        "for i in range(len(power)):\n",
        "  print(i)\n",
        "  poss, mod = get_mod_pos(power.iloc[i,7],power.iloc[i,8],power.iloc[i,0])\n",
        "  power.iloc[i,-1] = str(mod)\n",
        "  power.iloc[i,-2] = str(poss)"
      ],
      "metadata": {
        "id": "4vWkA5uwQmbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "power.to_csv('/content/output.csv')"
      ],
      "metadata": {
        "id": "y019oByFW8q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JHe2DSJJqjl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}